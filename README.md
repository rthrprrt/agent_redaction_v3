# Agent de rÃ©daction autonome

## To-do list

### Phase 0 â€“ Initialisation et infrastructure
1. **Configurer lâ€™environnement local** â€“ âœ”ï¸
2. **Tester Llama 3.1 Q8 via Ollama** â€“ âœ”ï¸
3. **Structurer dÃ©pÃ´t Git & CI lÃ©gÃ¨re** â€“ âœ”ï¸

### Phase 1 â€“ Ingestion et indexation
4. **Module dâ€™ingestion DOCX** â€“ âœ”ï¸
5. **PrÃ©traitement et segmentation** â€“ âœ”ï¸
6. **Indexation vectorielle (FAISS)** â€“ âœ”ï¸

### Phase 2 â€“ Extraction & planification
7. **Pipeline NLP extraction & anonymisation** â€“ âœ”ï¸
8. **RÃ©sumÃ© itÃ©ratif & raffinement** â€“ â—»ï¸
9. **GÃ©nÃ©ration de lâ€™ossature (plan)** â€“ â—»ï¸

### Phase 3 â€“ RÃ©daction & feedback
10. **RÃ©daction section par section** â€“ â—»ï¸
11. **Interface de feedback minimal** â€“ â—»ï¸
12. **Tests dâ€™intÃ©gration et Ã©valuation** â€“ â—»ï¸

## ProgrÃ¨s actuel

- Modules `loader.py`, `preprocessor.py`, `indexer.py`, `extractor.py` implÃ©mentÃ©s et testÃ©s.
- Environnement local configurÃ© (Python, venv, Git, pre-commit).
- ModÃ¨le Llama 3.1 Q8 opÃ©rationnel via Ollama.
- Data ingestion, nettoyage, segmentation, indexation RAG et extraction dâ€™entitÃ©s fonctionnels.

## Ã‰tapes suivantes

1. ImplÃ©menter la **RÃ©sumÃ© itÃ©ratif & raffinement** via LangChain RefineChain.
2. GÃ©nÃ©rer automatiquement lâ€™**ossature du rapport** (plan dÃ©taillÃ©).
3. DÃ©velopper la **rÃ©daction progressive** des sections.
4. Mettre en place lâ€™**interface de feedback** (CLI/notebook ou web).
5. RÃ©aliser les **tests dâ€™intÃ©gration** et ajuster les prompts.
6. (Optionnel) Ajouter UI web (Streamlit / FastAPI + React).
7. Documenter le pipeline et prÃ©parer la soutenance.

```mermaid
graph TD
    subgraph "ğŸ“š Knowledge Ingestion"
        A[Journal DOCX] --> B[loader.py]
        B --> C[preprocessor.py]
        C --> D[Text Chunks]
    end
    
    subgraph "ğŸ§  Agent Memory"
        D --> E[indexer.py]
        D --> F[extractor.py]
        E --> G[Vector Memory<br/>FAISS + Embeddings]
        F --> H[Entity Memory<br/>NER + PII Detection]
    end
    
    subgraph "ğŸ¤– AI Agent Core"
        I[Ollama LLM<br/>llama3.1:8b] --> J[Reasoning Engine]
        G -->|Retrieval| J
        H -->|Context| J
        J --> K[Report Generation]
    end
    
    subgraph "ğŸ“ Agent Output"
        K --> L[Structured Report]
        L --> M[Final Document]
    end
    
    subgraph "ğŸ”§ Agent Tools"
        N[SpaCy NLP] --> F
        O[Presidio Privacy] --> F
        P[SentenceTransformers] --> E
        Q[LangChain RAG] --> J
    end
    
    subgraph "ğŸ§ª Agent Testing"
        R[test_*.py] -.-> B
        R -.-> C
        R -.-> E
        R -.-> F
        R -.-> I
    end
    
    style I fill:#ff9800
    style J fill:#ff9800
    style G fill:#2196f3
    style H fill:#9c27b0
    style M fill:#4caf50
    style A fill:#e3f2fd
```
### Structure DÃ©taillÃ©e du Projet

```
agent-redaction-autonome/
â”œâ”€â”€ .flake8                           # Configuration linting Python
â”œâ”€â”€ .gitignore                        # Fichiers Ã  ignorer par Git
â”œâ”€â”€ .pre-commit-config.yaml          # Hooks de prÃ©-commit (Black, Flake8)
â”œâ”€â”€ README.md                         # Documentation principale du projet
â”œâ”€â”€ requirements.txt                  # DÃ©pendances Python
â”‚
â”œâ”€â”€ src/                             # Code source principal
â”‚   â”œâ”€â”€ __init__.py                  # Package Python
â”‚   â”œâ”€â”€ loader.py                    # Module d'ingestion des documents DOCX
â”‚   â”œâ”€â”€ preprocessor.py              # PrÃ©traitement et segmentation de texte
â”‚   â”œâ”€â”€ indexer.py                   # Indexation vectorielle avec FAISS
â”‚   â”œâ”€â”€ extractor.py                 # Extraction d'entitÃ©s et anonymisation PII
â”‚   â”‚
â”‚   â”œâ”€â”€ test_extractor.py           # Tests pour le module d'extraction
â”‚   â”œâ”€â”€ test_indexer.py             # Tests pour l'indexation vectorielle
â”‚   â”œâ”€â”€ test_ollama.py              # Test de connexion avec Ollama
â”‚   â””â”€â”€ test_preprocessor.py        # Tests pour le prÃ©traitement
â”‚
â”œâ”€â”€ data/                           # DonnÃ©es d'entrÃ©e
â”‚   â””â”€â”€ journal/                    # Fichiers DOCX du journal (*.docx)
â”‚       â”œâ”€â”€ YYYY-MM-DD_*.docx      # Format de fichiers attendu
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ db/                             # Base de donnÃ©es vectorielle
â”‚   â””â”€â”€ chroma/                     # Stockage FAISS/ChromaDB
â”‚
â”œâ”€â”€ venv/                           # Environnement virtuel Python
â”‚
â”œâ”€â”€ models/                         # ModÃ¨les et configurations IA
â”‚   â””â”€â”€ ollama/                     # Configuration Ollama
â”‚       â””â”€â”€ llama3.1:8b-instruct-q8_0  # ModÃ¨le LLM principal
â”‚
â”œâ”€â”€ output/                         # Fichiers de sortie gÃ©nÃ©rÃ©s
â”‚   â”œâ”€â”€ reports/                    # Rapports gÃ©nÃ©rÃ©s
â”‚   â”œâ”€â”€ summaries/                  # RÃ©sumÃ©s produits
â”‚   â””â”€â”€ plans/                      # Ossatures/plans gÃ©nÃ©rÃ©s
â”‚
â”œâ”€â”€ config/                         # Fichiers de configuration
â”‚   â”œâ”€â”€ prompts/                    # Templates de prompts
â”‚   â”‚   â”œâ”€â”€ extraction.yaml         # Prompts pour l'extraction
â”‚   â”‚   â”œâ”€â”€ summarization.yaml      # Prompts pour la rÃ©sumÃ©
â”‚   â”‚   â””â”€â”€ generation.yaml         # Prompts pour la gÃ©nÃ©ration
â”‚   â””â”€â”€ settings.yaml               # Configuration gÃ©nÃ©rale
â”‚
â”œâ”€â”€ pipeline/                       # Pipeline de traitement
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ ingestion.py               # Orchestration ingestion
â”‚   â”œâ”€â”€ processing.py              # Orchestration traitement
â”‚   â”œâ”€â”€ generation.py              # Orchestration gÃ©nÃ©ration
â”‚   â””â”€â”€ feedback.py                # Interface de feedback
â”‚
â”œâ”€â”€ utils/                          # Utilitaires
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ nlp_utils.py               # Utilitaires NLP
â”‚   â”œâ”€â”€ file_utils.py              # Utilitaires fichiers
â”‚   â””â”€â”€ logging_config.py          # Configuration des logs
â”‚
â”œâ”€â”€ tests/                          # Tests unitaires et d'intÃ©gration
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ unit/                       # Tests unitaires
â”‚   â”‚   â”œâ”€â”€ test_loader.py
â”‚   â”‚   â”œâ”€â”€ test_preprocessor.py
â”‚   â”‚   â”œâ”€â”€ test_indexer.py
â”‚   â”‚   â””â”€â”€ test_extractor.py
â”‚   â”œâ”€â”€ integration/                # Tests d'intÃ©gration
â”‚   â”‚   â”œâ”€â”€ test_pipeline.py
â”‚   â”‚   â””â”€â”€ test_end_to_end.py
â”‚   â””â”€â”€ fixtures/                   # DonnÃ©es de test
â”‚       â””â”€â”€ sample_journal.docx
â”‚
â”œâ”€â”€ notebooks/                      # Notebooks Jupyter pour prototypage
â”‚   â”œâ”€â”€ exploration.ipynb          # Exploration des donnÃ©es
â”‚   â”œâ”€â”€ model_testing.ipynb        # Test des modÃ¨les
â”‚   â””â”€â”€ evaluation.ipynb           # Ã‰valuation des rÃ©sultats
â”‚
â”œâ”€â”€ scripts/                        # Scripts d'automatisation
â”‚   â”œâ”€â”€ setup.py                   # Script d'installation
â”‚   â”œâ”€â”€ run_pipeline.py            # ExÃ©cution complÃ¨te du pipeline
â”‚   â””â”€â”€ evaluate_model.py          # Ã‰valuation du modÃ¨le
â”‚
â”œâ”€â”€ docs/                           # Documentation
â”‚   â”œâ”€â”€ architecture.md            # Architecture du systÃ¨me
â”‚   â”œâ”€â”€ api_reference.md           # RÃ©fÃ©rence API
â”‚   â””â”€â”€ user_guide.md              # Guide utilisateur
â”‚
â””â”€â”€ logs/                           # Fichiers de logs
    â”œâ”€â”€ application.log
    â”œâ”€â”€ error.log
    â””â”€â”€ performance.log
```

### Description des Modules Principaux

#### ğŸ“š **Modules d'Ingestion** (`src/`)
- **`loader.py`** : Chargement des fichiers DOCX avec extraction de dates
- **`preprocessor.py`** : Normalisation, segmentation et chunking du texte
- **`indexer.py`** : Indexation vectorielle avec FAISS et SentenceTransformers
- **`extractor.py`** : Extraction d'entitÃ©s (spaCy) + dÃ©tection/anonymisation PII (Presidio)

#### ğŸ¤– **Intelligence Artificielle**
- **ModÃ¨le LLM** : Llama 3.1 8B quantifiÃ© (Q8) via Ollama
- **Embeddings** : paraphrase-multilingual-MiniLM-L12-v2
- **NLP** : spaCy franÃ§ais (fr_core_news_sm)
- **RAG** : LangChain + FAISS pour la recherche sÃ©mantique

#### ğŸ”§ **Pipeline de Traitement**
1. **Ingestion** â†’ Lecture DOCX + extraction dates
2. **PrÃ©traitement** â†’ Normalisation + segmentation
3. **Indexation** â†’ Vectorisation + stockage FAISS
4. **Extraction** â†’ EntitÃ©s + anonymisation PII
5. **GÃ©nÃ©ration** â†’ RÃ©sumÃ©s + plans + rÃ©daction (Ã  implÃ©menter)

#### ğŸ§ª **Tests et Validation**
- Tests unitaires pour chaque module
- Tests d'intÃ©gration du pipeline complet
- Validation avec donnÃ©es d'exemple

#### ğŸ“Š **Ã‰tat d'Avancement**
- âœ… **Phase 1** : Ingestion et indexation (100%)
- âœ… **Phase 2** : Extraction et anonymisation (100%)
- â³ **Phase 3** : RÃ©sumÃ© itÃ©ratif et planification (0%)
- â³ **Phase 4** : RÃ©daction et feedback (0%)

### Technologies UtilisÃ©es

| Domaine | Technologies |
|---------|-------------|
| **LLM** | Ollama + Llama 3.1 8B |
| **NLP** | spaCy, LangChain, SentenceTransformers |
| **Privacy** | Presidio (Analyzer + Anonymizer) |
| **Vectorization** | FAISS, ChromaDB |
| **Documents** | python-docx |
| **Dev Tools** | Black, Flake8, pre-commit |
